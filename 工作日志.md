# 工作日志

## 8.12 Tue

任务：识别图像睁眼闭眼二分类任务

1.搜索学习二分类任务原理、基础、算法及常见解决方案

2.配置所需环境

3.处理数据集，设置划分训练/验证/测试集

4.完成基线设计：LBP局部二值模式+HOG方向梯度直方图+线性SVM

​	1）完成对全部代码的逐行理解

​	2）验证集准确度95.8%，测试集准确度95.42%，识别睁眼优秀

​	3）发现问题：出现闭眼图片低召回率问题，猜测是因为数据集类别不平衡导致（睁眼:闭眼 12.70:1）

5.下一步规划：

​	1）解决问题：解决类别不平衡导致的问题，考虑数据增强、样本均衡、特征优化等

​	2）进一步优化：采用CNN等主力模型，或微调其他轻量化网络，提升鲁棒性和检测能力

​	

## 8.13 Wed

1.详细学习LBP、HOG算法

2.解决因类别不平衡早层闭眼图片召回率低的问题

​	1）样本平衡

​		a.训练集欠采样1:1+类权重 ( acc: 96.99% (提升2%) , closed(1) recall: 73% (提升34%) )（比昨天）

​		b.欠采样1:1+类权重+特征标准化 ( acc: 96.66% (降0.33%) , closed(1) recall: 72% (降1%) )（比a）

​		c.欠采样1:1+去掉类权重 ( acc: 96.99% (不变) , closed(1) recall: 73% (不变) )（比a）（最佳）

​		d.欠采样1:1.2/1.5+去掉类权重 (结果比a差)

​		结论：选择 c.欠采样1:1+去掉类权重

​	2）少数类过采样（不采用）

​		a.纯过采样+欠采样=0 ( acc: 95.23% (差) , closed(1) recall: 37% (差) )（不采用）

​		b.先欠采样（1.5），再过采样1:1 ( acc: 96.04% , closed(1) recall: 60% (差) )（不采用）

​		结论：回到 c.欠采样1:1+去掉类权重

​	3）数据增强（不采用）

​		a.对闭眼样本进行轻微增强 水平翻转+亮度扰动+小角度旋转+高斯模糊（组合不同增强方式，均效果差）

​		结论：回到 c.欠采样1:1+去掉类权重

​	最终方案：欠采样1:1+去掉类权重( acc: 96.99% , closed(1) recall: 73% )，达到SVM最优水平

3.进入新阶段：尝试小型CNN

​	1）设计代码架构

​	2）目标：跑通模型，建立深度学习baseline

​	3）先跑较少epoch看趋势

4.下一步规划：

​	1）逐步进行微调，闭眼closed(1) recall超过SVM

​	2）验证预训练模型MobileNet/ShuffleNet/EfficientNet等

​	3）本阶段目标 acc >= 0.97 & closed(1) recall >= 0.80



## 8.14 Thu

1.学习pytorch中transforms机制图片数据预处理方法及所属torchvision计算机视觉工具包

2.学习len方法、getitem方法、torch.utils.data包中的Dataset、DataLoader类

3.学习nn.BCEWithLogitsLoss()用法，针对二分类问题，解决sigmoid激活函数用两遍导致的bug

4.使用seed固定随机源，测试结果可复现

5.了解一些优化算法，尤其是Adam和AdamW优化器，AdamW权重衰减可直接作用于参数而不修改梯度

6.完成小型CNN初版代码编写（acc:93.03% closed recall很差，训练结果一般）

​	1）数据集部分

​		a.对训练集进行图像预处理

​		b.使用WeightedRandomSampler解决解决类别不平衡问题

​	2）模型设计：轻量CNN

​		a.特征提取：4组卷积块 128x128 to 8x8

​		b.分类：压缩到1维值，便于二分类

​	3）代码增加可视化部分，便于监控进度及结果

​	4）后期考虑尝试使用DSConv

7.下一步规划：在本模型基础上优化，待较为成熟再尝试预训练模型

问题总结：

1.对pytorch的使用不熟悉，需要大量学习，较为影响进度推进

2.在验证集中，要么睁眼识别好，闭眼识别不好，要么闭眼好，睁眼不好



## 8.15 Fri

1.尝试使用ResNet18

​	1）模型结构：两层ResNet18，全连接改1输出

​	2）迁移至RTX 4090，启用CUDA+AMP，训练吞吐量显著提升（5.5-6it/s 1500-1600img/s)

​	3）使用ImageNet预训练，收敛快

​	4）增大Batch和学习率

​	5）有关消融实验：预训练、数据增强、Batch Size、学习率、AMP

​	6）成果：验证集acc首次突破99%，但loss不稳定，无法一直持续。测试集未达99%+的预期。

​		（[val] acc=99.14% open recall=99% closed recall=95%)（最佳数据）

​	7）测试了在SVM表现优秀的欠采样1:1，在本模型中acc始终无法突破99%（98.5%+）

​		（[TEST] acc=98.85% open recall=100% closed recall=90%)

​	8）偶然发现之前的大版本使用灰度图，改到ResNet后未改，改到RGB后，能力提升。

​	9）易过拟合，几乎到第3-4个epoch时就是最好的，但无法达到99.5%+

2.配置服务器环境，学习SSH连接服务器技术，解决本地端上传服务器断点续传问题

3.需解决问题：

​	a.训练集loss收敛良好但验证集loss波动极大

​	b.保存验证集中表现良好的模型



## 8.18 Mon

1.主要工作

​	1）测试并改进现有程序，增加三分类功能（open / closed / uncertain），输出预测结果到 .csv

​	2）学习并实践 ResNet34 / ResNet50 网络结构，当前主干网络采用 ResNet34

2.发现与改进

​	1）数据集中存在大量脏数据，尤其是半睁半闭的情况，影响二分类精度

​	2）将任务由二分类改为三分类：

​		a.重新划分数据集

​		b.依据置信度设置uncertain类别，辅助数据清洗

​		c.输出三分类结果 .csv，便于后续筛查

3.下一步规划

​	1）清洗出高质量约1k:1k的睁眼/闭眼数据集

​	2）使用清洗后的数据重新训练，目标是进一步提升模型精度与稳定性

## 8.19 Tue

1.修改算法，对训练集、测试集、验证集进行预测与标签比对

2.人工清洗数据集

3.学习Vision Transformers



## 8.20 Wed

1.深入学习Vision Transformers相关知识

2.清洗出530:530的睁眼闭眼训练集，并进行测试。

3.使用ViT重新编写代码

4.下一步规划：完成剩余代码编写，跑通代码



## 8.21 Thu

1.ViT模型设计

​	1）图片打块：用一个卷积层将图像划分为 patch 并映射为向量序列 16*16

​	2）位置编码：引入可学习位置向量 、 cls token机制

​	3）多头自注意力：QKV 投影，多头并行建模 patch 间全局依赖关系

​	4）标准 Transformer 块：LayerNorm → Attention → 残差、LayerNorm → MLP → 残差

​	5）MLP 设计：两层全连接，激活函数 GELU

​	6）输出：取 cls token 作为图像整体表示，接线性层输出二分类结果

​	初步测试结果：acc=0.9111 open recall：0.89  closed recall:0.93)

​         [   TP42   FN 5   ]
​         [   FP 3    TN40  ]

2.学习了解timm库

3.详细学习多头自注意力、MLP多层感知、Transformer的代码编写



## 8.22 Fri

1.重新理解网络结构，详细理解计算过程

2.学习适合论文的结构图、示意图的画法，安装使用相关工具

3.按照模型及代码结构绘图



## 8.25 Mon

1.完成模型结构图的绘制

2.对潜在合适的模型进行调研

3.对 ViT Baseline 进行优化（改进方向）

​	1）更换ViT预训练底座，采用timm（vit_base_patch14_reg4_dinov2.lvd142m）进行测试，并保持pipeline		不变。

​	2）解决预训练模型与实际先前模型尺寸不匹配问题

​	3）由于数据量较小，采用分阶段解冻和不同层控制不同学习率的策略

4.下一步计划：完成以上测试，并尝试更多潜在可用模型



## 8.26 Tue

1.跑通ViT timm版本，在小数据集时表现还可以

2.搜索数据集，获取约84000张已分类眼部数据集（睁闭眼约1:1）MRL Eye Dataset、cuhk的数据集约20万张人脸照片

3.使用MRL Eye Dataset，目前未运行完一轮，但val集结果较好，acc大于98.8%，open recall大于99%，close recall大于98%，闭眼recall有波动，有时97%，需要优化，运行速度上待优化。

例：验证集 VAL ACC=0.9854

[4117  52]

 [ 68 4005]

​                     precision  recall f1-score  support

   open(0)    0.98             0.99     0.99      4169

  closed(1)    0.99            0.98     0.99       4073



## 8.27 Wed

1.出现问题：val集是从train集中随机抽出来，但忽略掉train集中存在同一人的多张照片，导致val集数据很好，但test集测试结果不够好。需调整val集。

2.调整val集后，运行acc大约95%-96%左右。发现问题：该数据集虽然看上去图片多，但实际上是同一个人的很多照片，而采集的人数也就几十人，样本特征变化少，表现一般。该数据集特征较为简单，多为正面照，特征明显

TEST集 acc=0.9730

[1577  80]

 [ 7 1559]

​                     precision  recall f1-score  support

   open(0)    1.00             0.95     0.97      1657

  closed(1)    0.95            1.00     0.97       1566

<img src="https://typora-image-for-wilsonxin.oss-cn-beijing.aliyuncs.com/ViT_loss_curve_80k%20(1).png" alt="ViT_loss_curve_80k (1)" style="zoom: 25%;" />

图像解释：图像符合OneCycleLR动态调整学习率的策略，前面波动大，后面逐渐稳定

评论：目前无论是val还是test，都基本都基本较稳定，后期有轻微过拟合，将根据人物特点进行微调，本次运行较有意义，是在 ViT+大数据集 中首次获取的数据，将设定新Baseline



3.对原来的小数据集（800张）进行扩图，每张扩出25张图，生成大约20000张图

4.最终还是回归原数据集，先拿原数据集进行测试。

5.返回之前的resnet，使用扩图后的数据集（20000张）进行测试

​	1）测试数据较好，过拟合快，val落在99%-100%，test落在97%（怀疑是模型保存策略问题）

6.未来方向：

​	1）考虑使用较重模型进行蒸馏

​	2）使用不同角度，戴眼镜等新图片进行测试



## 8.28 Thu

1.整理代码、成果

